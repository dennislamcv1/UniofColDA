{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjc0tic+2V2Fc7O/I5JA9N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Case Study Iris\n","Let's proceed with the tutorial on hierarchical clustering using the \"Iris\" dataset. We will demonstrate the agglomerative hierarchical clustering method, which is a popular hierarchical clustering approach."],"metadata":{"id":"9o2xsdlj8Ze2"}},{"cell_type":"markdown","source":["## Setup\n","Dataset Loading and Exploration"],"metadata":{"id":"_ps9VNTq8fJr"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9v8_BfEr8Wmo","executionInfo":{"status":"ok","timestamp":1690655930396,"user_tz":240,"elapsed":2154,"user":{"displayName":"Di Wu","userId":"05255951341257561169"}},"outputId":"f005bed4-6e39-4189-caeb-24fa97a26217"},"outputs":[{"output_type":"stream","name":"stdout","text":["   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","   target  \n","0     0.0  \n","1     0.0  \n","2     0.0  \n","3     0.0  \n","4     0.0  \n","       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n","count         150.000000        150.000000         150.000000   \n","mean            5.843333          3.057333           3.758000   \n","std             0.828066          0.435866           1.765298   \n","min             4.300000          2.000000           1.000000   \n","25%             5.100000          2.800000           1.600000   \n","50%             5.800000          3.000000           4.350000   \n","75%             6.400000          3.300000           5.100000   \n","max             7.900000          4.400000           6.900000   \n","\n","       petal width (cm)      target  \n","count        150.000000  150.000000  \n","mean           1.199333    1.000000  \n","std            0.762238    0.819232  \n","min            0.100000    0.000000  \n","25%            0.300000    0.000000  \n","50%            1.300000    1.000000  \n","75%            1.800000    2.000000  \n","max            2.500000    2.000000  \n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 150 entries, 0 to 149\n","Data columns (total 5 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   sepal length (cm)  150 non-null    float64\n"," 1   sepal width (cm)   150 non-null    float64\n"," 2   petal length (cm)  150 non-null    float64\n"," 3   petal width (cm)   150 non-null    float64\n"," 4   target             150 non-null    float64\n","dtypes: float64(5)\n","memory usage: 6.0 KB\n","None\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import AgglomerativeClustering\n","from scipy.cluster.hierarchy import dendrogram, linkage\n","\n","# Load the Iris dataset\n","data = load_iris()\n","X, y = data.data, data.target\n","\n","# Convert to DataFrame for easier manipulation (optional)\n","df = pd.DataFrame(data=np.c_[X, y], columns=data.feature_names + ['target'])\n","\n","# Explore the dataset\n","print(df.head())\n","print(df.describe())\n","print(df.info())"]},{"cell_type":"markdown","source":["## Data Preprocessing\n","Before applying hierarchical clustering, we need to preprocess the data to standardize the features."],"metadata":{"id":"io0Vo1Kl8i8s"}},{"cell_type":"code","source":["# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"c0boZqL18lA4","executionInfo":{"status":"ok","timestamp":1690655939966,"user_tz":240,"elapsed":15,"user":{"displayName":"Di Wu","userId":"05255951341257561169"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Agglomerative Hierarchical Clustering"],"metadata":{"id":"MJ9N_i6O8nhO"}},{"cell_type":"code","source":["# Initialize the Agglomerative clustering algorithm with a specific number of clusters (n_clusters)\n","agglomerative = AgglomerativeClustering(n_clusters=3)\n","\n","# Fit the model to the data\n","agglomerative.fit(X_scaled)\n","\n","# Get the cluster assignments for each sample\n","agglomerative_labels = agglomerative.labels_\n","\n","print(f\"Agglomerative Hierarchical Clustering:\")\n","print(f\"Cluster Assignments: {agglomerative_labels}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nekxoehJ8pXu","executionInfo":{"status":"ok","timestamp":1690655957898,"user_tz":240,"elapsed":17,"user":{"displayName":"Di Wu","userId":"05255951341257561169"}},"outputId":"b7b39ebc-8ca6-46ac-9641-c8ff199beeb4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Agglomerative Hierarchical Clustering:\n","Cluster Assignments: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 2 1 1 1 1 1 1 1 1 0 0 0 2 0 2 0 2 0 2 2 0 2 0 2 0 2 2 2 2 0 0 0 0\n"," 0 0 0 0 0 2 2 2 2 0 2 0 0 2 2 2 2 0 2 2 2 2 2 0 2 2 0 0 0 0 0 0 2 0 0 0 0\n"," 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0]\n"]}]}]}